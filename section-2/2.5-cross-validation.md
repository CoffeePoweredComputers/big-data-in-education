# Cross-Validation and Over-Fitting

##### Reducing Over-Fitting:
* Use simpler models:
  * Fewer variables (BiC, AIC, follow Occam's Razor)
  * Less complex function (MDL)
* Splitting data into Training/Testing sets.
* Using k-fold cross validation.
* Mixed Methods of the former two.

##### How many groups?
* K-Fold:
  * Pick a number k, split into this number of groups.
  * Quicker, preferred by some theoreticians.
* Leave-Out-One
  * Every data point is a fold.
  * More stable.
  * Avoids issue of how to select folds (stratification issues).

##### Cross-Validation Variants:
* Flat Cross-Validation -> Each point has equal chance of being placed into each fold.
* Stratified Cross-Validation:
  * Biases fold selection so that some variable is equally represented in each fold.
  * The variable you're trying to predict.
  * Or some variable that is thought to be an important context.
* Student-Level Cross-Validation -> Folds are selected so that no student's data is represented in two folds. This is seen as the __minimum__ cross validation needed in the EDM conference.
* Other cross validation levels:
  * Lesson
  * School
  * Demographic 
  * Software package
  * Sessions

