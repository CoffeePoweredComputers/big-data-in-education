# Classifiers

##### Where do labels come from:
* In software performance
* School records
* Test data
* Survey data
* Field observations or video coding
* Test replays

##### Useful Algorithms:
* Step Regression
* Logistic Regression
* J48/C4.5 Decision Trees
* JRip Decision Rules
* K\* Instance-Based Classifiers


##### Step Regression:
* Fits a linear regression function
* Selects parameters
* Assigns a weight to each parameters
* Computes a numerical value
* Should you use it:
 * Cons: No closed form so difficult to compute standard error
 * Pros: Conservative in data mining context, tends not to over fit
* Not good for taking into account interaction effects (e.g. A=Bad B=Bad but A+B=Good)

##### Logistic Regression:
* Used for binary classification
* Fits logistic function to data to find out the frequency or dds of a specific value of the dependent variable
* pm(m) = 1/(1 + e^{-m})
* Good for cases where changes in the value of a predictor variable have predictable effects on probability of predicted variable class.
* Not good for taking into account interaction effects (e.g. A=Bad B=Bad but A+B=Good)

##### Decision Trees:
* More directly deals with interaction effects.
* J48/C4.5:
  * Can handle both numerical and categorical predictor variables. Tries to find optimal split in numerical variables
  * Repeatedly looks for variable which best splits the data in terms of predictive power. 
  * Prunes Btu branches that turn out to have low predictive power
  * Note that different branches can Hae different features!
  * Can be split based on more or less evidence or to prune based on predictive power.
  * Pros: Good on bimodal datasets, multi-level interactions are common, same construct can be arrived through multiple avenues, fairly conservative in prediction.
  *

##### What variables should you use:
* Some variables have more construct validity or theoretical justification than others- using those variable generally leads to more generalizable models.
* Some variables will make you model general only to the data set where they were trained and should be only used during cross validation, not during training.
* In modern statistics, you often need to explicitly include these types of variables in models to conduct valid statistical testing.
